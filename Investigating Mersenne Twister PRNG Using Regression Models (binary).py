# Task: Provided a sequence of numbers generated by the random module, find its seed.
# Python uses MT19937, and observing at least 624 of iterations allows one to predict all future iterations.

"""
seed(self, a=None, version=2)
     |      Initialize internal state from hashable object.
     |      
     |      None or no argument seeds from current time or from an operating
     |      system specific randomness source if available.
     |      
     |      If *a* is an int, all bits are used.
     |      
     |      For version 2 (the default), all of the bits are used if *a* is a str,
     |      bytes, or bytearray.  For version 1 (provided for reproducing random
     |      sequences from older versions of Python), the algorithm for str and
     |      bytes generates a narrower range of seeds.
"""

# We will assume that seed provided is an integer.
# We will use getrandbits(32)

import random

def generate_seeds():
    min_seed = 0
    max_seed = 2 ** 32
    sample_size = 2 ** 15
    
    csprng = random.SystemRandom()
    seeds = csprng.sample(range(min_seed, max_seed + 1), sample_size)
    mid = len(seeds) // 2
    train_seeds = sorted(seeds[:mid])
    test_seeds = sorted(seeds[mid:])
    return train_seeds, test_seeds

def generate_train_file(train_seeds):
    with open("mersenne_train.csv", "w") as f:
        f.write(",".join(["y"] + [f"x{index + 1}" for index in range(624) for bit in range(32)]) + "\n")
        for seed in train_seeds:
            random.seed(seed)
            f.write(",".join([str(seed)] + [bit for _ in range(624) for bit in f"{int(bin(random.getrandbits(32))[2:]):032d}"]) + "\n")
        f.close()

def generate_test_file(test_seeds):
    with open("mersenne_test.csv", "w") as f:
        f.write(",".join(["y"] + [f"x{index + 1}_{bit + 1}" for index in range(624) for bit in range(32)]) + "\n")
        for seed in test_seeds:
            random.seed(seed)
            f.write(",".join([str(seed)] + [bit for _ in range(624) for bit in f"{int(bin(random.getrandbits(32))[2:]):032d}"]) + "\n")
        f.close()

##train_seeds, test_seeds = generate_seeds()
##generate_train_file(train_seeds)
##generate_test_file(test_seeds)

import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

train_dataset = pd.read_csv("mersenne_train.csv")
y = train_dataset["y"]
X = train_dataset.drop(["y"], axis = 1)

test_dataset = pd.read_csv("mersenne_test.csv")
y_test = test_dataset["y"]
X_test = test_dataset.drop(["y"], axis = 1)

from sklearn.ensemble import RandomForestRegressor

regressor = RandomForestRegressor()
regressor.fit(X, y)
y_pred = regressor.predict(X_test)
y_pred = y_pred.astype(int)
print(accuracy_score(y_test, y_pred))
print(precision_score(y_test, y_pred, average = "micro"))
print(recall_score(y_test, y_pred, average = "micro"))
print(f1_score(y_test, y_pred, average = "micro"))

##from sklearn.ensemble.forest import RandomForestRegressor
##from sklearn.ensemble.forest import ExtraTreesRegressor
##from sklearn.ensemble.bagging import BaggingRegressor
##from sklearn.ensemble.gradient_boosting import GradientBoostingRegressor
##from sklearn.ensemble.weight_boosting import AdaBoostRegressor
##from sklearn.gaussian_process.gpr import GaussianProcessRegressor
##from sklearn.isotonic import IsotonicRegression
##from sklearn.linear_model.bayes import ARDRegression
##from sklearn.linear_model.huber import HuberRegressor
##from sklearn.linear_model.base import LinearRegression
##from sklearn.linear_model.passive_aggressive import PassiveAggressiveRegressor 
##from sklearn.linear_model.randomized_l1 import RandomizedLogisticRegression
##from sklearn.linear_model.stochastic_gradient import SGDRegressor
##from sklearn.linear_model.theil_sen import TheilSenRegressor
##from sklearn.linear_model.ransac import RANSACRegressor
##from sklearn.multioutput import MultiOutputRegressor
##from sklearn.neighbors.regression import KNeighborsRegressor
##from sklearn.neighbors.regression import RadiusNeighborsRegressor
##from sklearn.neural_network.multilayer_perceptron import MLPRegressor
##from sklearn.tree.tree import DecisionTreeRegressor
##from sklearn.tree.tree import ExtraTreeRegressor
##from sklearn.svm.classes import SVR
##from sklearn.linear_model import BayesianRidge
##from sklearn.cross_decomposition import CCA
##from sklearn.linear_model import ElasticNet
##from sklearn.linear_model import ElasticNetCV
##from sklearn.kernel_ridge import KernelRidge
##from sklearn.linear_model import Lars
##from sklearn.linear_model import LarsCV
##from sklearn.linear_model import Lasso
##from sklearn.linear_model import LassoCV
##from sklearn.linear_model import LassoLars
##from sklearn.linear_model import LassoLarsIC
##from sklearn.linear_model import LassoLarsCV
##from sklearn.linear_model import MultiTaskElasticNet
##from sklearn.linear_model import MultiTaskElasticNetCV
##from sklearn.linear_model import MultiTaskLasso
##from sklearn.linear_model import MultiTaskLassoCV
##from sklearn.svm import NuSVR
##from sklearn.linear_model import OrthogonalMatchingPursuit
##from sklearn.linear_model import OrthogonalMatchingPursuitCV
##from sklearn.cross_decomposition import PLSCanonical
##from sklearn.cross_decomposition import PLSRegression
##from sklearn.linear_model import Ridge
##from sklearn.linear_model import RidgeCV
##from sklearn.svm import LinearSVR
